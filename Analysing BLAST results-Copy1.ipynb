{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fasta import *\n",
    "import alignment\n",
    "import utilities\n",
    "from checkGenome import *\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import *\n",
    "from traitlets import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files\n",
    "\n",
    "The first thing we want to do is load in our files. Loading them in this way actually loads them into a dictionary where the keys are the record IDs and the values are the full records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'files/2U1_all_candidates_PSI_BLAST_unique.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3df3b756f780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the 2U1 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfull_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"files/2U1_all_candidates_PSI_BLAST_unique.fasta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# full_record = SeqIO.to_dict(SeqIO.parse(\"files/Python_bivittaus_full_PSI.fasta\", \"fasta\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# full_record = SeqIO.to_dict(SeqIO.parse(\"files/2U1_and_2U1_like_candidates_BLAST_results_unique_X_seqs_removed.fasta\", \"fasta\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# full_record = SeqIO.to_dict(SeqIO.parse(\"files/fGMC-3-2_GOX_GDH-3_SS_only_species.fasta\", \"fasta\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/Bio/SeqIO/__init__.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(sequences, key_function)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/Bio/SeqIO/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(handle, format, alphabet)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid alphabet, %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mas_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;31m# Map the file format to a sequence iterator:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_FormatToIterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/Bio/File.py\u001b[0m in \u001b[0;36mas_handle\u001b[0;34m(handleish, mode, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandleish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'files/2U1_all_candidates_PSI_BLAST_unique.fasta'"
     ]
    }
   ],
   "source": [
    "# Load the 2U1 files\n",
    "# full_record = SeqIO.to_dict(SeqIO.parse(\"files/2U1_all_candidates_PSI_BLAST_unique.fasta\", \"fasta\"))\n",
    "# full_record = SeqIO.to_dict(SeqIO.parse(\"files/Python_bivittaus_full_PSI.fasta\", \"fasta\"))\n",
    "# full_record = SeqIO.to_dict(SeqIO.parse(\"files/2U1_and_2U1_like_candidates_BLAST_results_unique_X_seqs_removed.fasta\", \"fasta\"))\n",
    "# full_record = SeqIO.to_dict(SeqIO.parse(\"files/fGMC-3-2_GOX_GDH-3_SS_only_species.fasta\", \"fasta\"))\n",
    "# full_record = SeqIO.to_dict(SeqIO.parse(\"files/71AV.fasta\", \"fasta\"))\n",
    "#full_record = SeqIO.to_dict(SeqIO.parse(\"files/homo_sapiens.fasta\", \"fasta\"))\n",
    "\n",
    "# full_record = SeqIO.to_dict(SeqIO.parse(\"files/candidates/regextest.fasta\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many sequences do we have in the full records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (len(full_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for record in full_record:\n",
    "    print (full_record[record].description)\n",
    "    print (full_record[record].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating subsets of the records\n",
    "### Including / excluding based on header annotations\n",
    "\n",
    "Now the workflow moves to including and excluding certain sequences. `subset_records` allows us to provide a list of terms which we either want or don't want in the header description. We can also give a minimum length for sequences to meet for inclusion.\n",
    "\n",
    "We don't ever alter the original `full_record`, we just create new dictionary objects that are subsets.\n",
    "\n",
    "We can either provide arguments directly to the function or we can pass in a list variable, such as `header_terms`.\n",
    "\n",
    "In the example below `only_2U1_records` is set to only include sequences which have either '2U1' or '2U1-like' in the header. And `filtered_records` will contain the full set of sequences as we are not providing a length minimum (and the default is 0) and we are passing in the currently empty `header_terms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A blank list to hold terms we want to exclude or include\n",
    "header_terms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_2U1_records = subset_records(\"2U1\", \"2U1-like\", records=full_record, length=400, mode=\"include\")\n",
    "filtered_records = subset_records(*header_terms, records=full_record, length=500, mode='exclude')\n",
    "\n",
    "print (\"The number of sequences with either 2U1 or 2U1-like in the header is %s \" % (len(only_2U1_records)))\n",
    "print (\"The number of sequences we've filtered is %s which should be equal to %s\" % (len(filtered_records), len(full_record)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adding terms to the `header_terms` variable\n",
    "The following section makes it easy to add in terms to the `header_terms` variable and to save these files for later use.\n",
    "\n",
    "Let's first print out the terms in our variable and the length of it. As you add to the list you can always come back and rerun this cell to peek inside the `header_terms` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (header_terms)\n",
    "print (len(header_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we might be interested in doing is to print out the header information of the sequences we currently have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for record in filtered_records:\n",
    "    print (filtered_records[record].description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will add items to our `header_terms` variable. Hit run on the cell and you'll see an input box - simply add words seperated by a space that you want to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add = widgets.Text()\n",
    "display(add)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    for item in add.value.split():\n",
    "        header_terms.append(item)\n",
    "    print (header_terms)\n",
    "add.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can also remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = widgets.Text()\n",
    "display(remove)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    for item in remove.value.split():\n",
    "        header_terms.remove(item)\n",
    "    print (header_terms)\n",
    "\n",
    "remove.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is that cell that lets us check all the words in `header_terms` so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (header_terms)\n",
    "print (len(header_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a play around with adding and removing words to the `header_terms` list and then the following cells illustrate how it can be used.\n",
    "\n",
    "Make the `header_terms` list contain just the terms \"2B4\" and \"2B4-like\" and then we'll create a new record called `only_2B4_records`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_2B4_records = subset_records(*header_terms, records=full_record, mode='include')\n",
    "for record in only_2B4_records:\n",
    "    print (only_2B4_records[record].description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the header terms variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utilities.saveHeaderTerms(header_terms, \"files/headerterms.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_terms = utilities.loadHeaderTerms(\"files/headerterms.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting record files using regular expressions\n",
    "Typing all of the particular items we want to include or exclude can be time-consuming, and often we want to include or exclude all of the members of a family. So we can use regular expressions in `subset_records_with_regex` and only supply the first part of the family name and have it automatically match to all headers that contain text starting with that first part.\n",
    "\n",
    "For example - excluding \"2J\" would exclude \"2J6\", \"2J2\", and \"2J2-like\" (as well as others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_records = subset_records_with_regex(\"subfamily A\", \"subfamily a\",\"subfamily 2 J19\", \"Cyp2c38\", \"subfamily D\", \"subfamily d\", \"subfamily E\", \"subfamily e\", \"subfamily AA\", \"subfamily C\", \"subfamily X\", \"subfamily x\", \"subfamily c\", \"subfamily J\", \"subfamily j\", \"subfamily AD\", \"subfamily ad\", \"subfamily B\", \"subfamily b\", \"subfamily k\", \"subfamily K\", \"2U\", \"2D\", \"2J\", \"2B\", \"2A\", \"2B\", \"2C\", \"2D\", \"2E\", \"2F\", \"2G\", \"2H\", \"2I\", \"2J\", \"2K\", \"2L\", \"2M\", \"2N\", \"2O\", \"2P\", \"2Q\", \"2R\", \"2S\", \"2T\", \"2V\", \"2W\", \"2X\", \"2Y\", \"2Z\", \"1A\", \"1B\", \"76C\", \"84A\", \"98A\", \"304a1\", \"305a1\", \"306a1\", \"CYP17A\", \"303a1\", \"307a1\", \"83B\", \"81E\", \"81d1\", \"81D1\", \"18\",    records=full_record, mode=\"exclude\")\n",
    "# test_records = subset_records_with_regex(\"2U\", records=full_record, mode=\"include\")\n",
    "# test_records = subset_records(\"uncharacterized\", \"25-hydroxylase\", \"partial\", \"hypothetical\", \"unnamed\", \"Cyp2r1\", records=test_records, mode='exclude')\n",
    "\n",
    "print (len(test_records)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species_counts = build_species_count(records=test_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in test_records:\n",
    "    print (test_records[item].description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating how many hits per species\n",
    "\n",
    "`build_species_count` builds a dictionary which has the set of unique species as its keys and a list of the sequence IDs that belong to each unique species as its . So we can use it to easily see how many unique species we have and which species are over represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species_counts = build_species_count(records=full_record)\n",
    "print(\"There are %s unique species in our dataset.\" % (len(species_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the frequency of proteins per species\n",
    "`plot_record_number` is a function that plots the numbers of IDs per species. We can set a minimum number of IDs that a species must have in order to be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotthis = plot_record_number(species_counts, \"Bar\", min=3)\n",
    "py.iplot(plotthis, filename='inline_bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotthis = plot_record_number(species_counts, \"Bar\", min=2)\n",
    "py.iplot(plotthis, filename='inline_bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotthis = plot_record_number(species_counts, \"Bar\", min=5)\n",
    "py.iplot(plotthis, filename='inline_bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also just extract the names using `get_species_name`, which also accepts a minimum number of IDs required and can print out the number of counts per each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "species_names = get_species_names(species_counts, min=1)\n",
    "for name in species_names:\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species_names_with_counts = get_species_names(species_counts, min=3, counts=True)\n",
    "for name in species_names_with_counts:\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the total number of sequences with multiple hits\n",
    "`count_ids` is a function that counts the total number of sequences in a species count dictionary, not just the number of unique species.\n",
    "\n",
    "As before, it can also take a minimum number of IDs required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_num = 5\n",
    "print (\"There are %s total sequences in our filtered dataset.\" % (count_ids(species_counts)))\n",
    "print (\"There are %s total sequences in our filtered dataset that have %d or more IDs per species.\" % (count_ids(species_counts, min=min_num), min_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generating datasets containing information about species with multiple hits\n",
    "For each species that has more than the given number of hits, we create \n",
    "1. A FASTA file of the protein sequences from that species\n",
    "2. An alignment of the protein sequences\n",
    "3. An information file telling use where in the genome the protein maps to\n",
    "4. A visual diagram of the genome mapping the proteins to the genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_multiple_hit_data(species_names, species_counts, full_record, file_path):\n",
    "    id_dict = {}\n",
    "#     for name in species_names:\n",
    "#         seqs = map_species_to_records(species_counts[name], full_record)\n",
    "#         write_fasta(seqs, file_path + name + \" sequences\")\n",
    "#         alignmentFile = alignment.alignWithMAFFT(file_path + name + \" sequences\")\n",
    "#         alignment.writeAlignment(alignmentFile, file_path + name + \".aln\", \"fasta\")\n",
    "        \n",
    "\n",
    "    check_genomic_location(species_counts, min=1, file_path=file_path +\" gene locations \")\n",
    "    check_genomic_location(species_counts, min=1, visualise=\"linear\")\n",
    "\n",
    "\n",
    "species_names = get_species_names(species_counts, min=1)\n",
    "generate_multiple_hit_data(species_names, species_counts, full_record, \"files/multiple_hits/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could just use parts of this function. The cell below will just print out the locations of the proteins in the genome. We could save this to disk by providing an argument to the `file_path` variable or visualise it by providing either 'linear' or 'circular' to the `visualise` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_genomic_location(species_counts, min=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the records to FASTA files\n",
    "Because `filtered_records` just contains the species name and IDs of these species, we need to map these IDs back to their full records. We can use the function `map_ids_to_records` which allows for us to select all the records in `filtered_ids` or just the unique species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_records = map_ids_to_records(species_counts, full_record)\n",
    "filtered_records_unique = map_ids_to_records(species_counts, full_record, unique=True)\n",
    "\n",
    "# Check that the numbers are correct\n",
    "print (len(filtered_records))\n",
    "print (len(filtered_records_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can save these records to a new FASTA file using `write_fasta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_fasta(filtered_records, \"files/2U1_BLAST_smaller_records.fasta\")\n",
    "# write_fasta(filtered_records_unique, \"files/2U1_BLAST_filtered_records_unique.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the function `map_species_to_records` to just map a particular species to a FASTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priapulus_caudatus = map_species_to_records(species_counts['Priapulus caudatus'], full_record)\n",
    "write_fasta(priapulus_caudatus, \"files/priapulus_caudatus.fasta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
